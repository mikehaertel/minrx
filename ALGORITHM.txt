Part I: Structured Non-deterministic Finite Automata (SNFA)

MinRX is an Non-deterministic Finite Automaton (NFA) based regular
expression matcher that introduces a new algorithm and automaton
structure for computing the matching substrings of POSIX Extended Regular
Expressions (EREs).  I call this enhanced automaton a Structured NFA,
abbreviated SNFA.  It could also possibly be called a Stacked NFA with
the same abbreviation.

Here is some background material for readers not already familiar with
conventional NFA-based regular expression matchers:

https://en.wikipedia.org/wiki/Thompson%27s_construction
https://en.wikipedia.org/wiki/Nondeterministic_finite_automaton

The rest of this description is concerned with first briefly describing
the conventional aspects of MinRX's algorithm, followed by a more detailed
description of the differences between MinRX and the traditional algorithm.

As is conventional, the MinRX SNFA is constructed using Thompson's
construction (with slight modifications) and includes both nodes that
consume and match input characters (from the string being searched),
as well as nodes, called epsilon-matching nodes, that "match the empty
string" and do not consume input characters.

As is also conventional, the MinRX matcher executes by exploring all
possible paths through the SNFA in parallel using breadth-first search,
consuming one input character per iteration.  MinRX creates and maintains
a collection of "non-deterministic states", called NStates in the MinRX
source code, that each record information pertaining to a particular
location in the SNFA and the text that was matched so far in order
to reach that location.  Each NState represents a match-in-progress.

The matcher is initialized by introducing a single NState associated
with the initial entry node (a.k.a. start state) of the SNFA.  Then the
matcher performs an "epsilon closure", exhaustively finding the set of
all nodes reachable from the start state by traversing outgoing edges
of only epsilon-matching nodes in the SNFA.  The output of this initial
epsilon closure is a collection of NStates that together comprise the
state of the matcher prior to consuming the first input character.

After initialization the matcher loops over input characters, performing
the following operations for each input character:

  * discard all NStates at epsilon-matching nodes

  * advance only those remaining NStates at character-matching nodes
    that actually match the current input character

  * introduce a new NState at the start state (in order to explore
    matches at all possible starting offsets in the search string)

  * perform epsilon closure on the set of NStates so far

These steps are repeated until there are no more input characters.

If the Exit node of the SNFA is reached during this process, then a
match has been found and the algorithm will prioritize it against any
other matches that have also been found in order to identify the "best"
match, according to criteria that will be described later.

Each NState is labeled with the position in the input string at which
the path leading to the NState was first introduced to the search.
Whenever two NState reach the same node in the SNFA, only the NState that
originated earlier in the search string is retained.  This ensures that
MinRX will find the longest match.  If two NStates with the same starting
position advance to the same node, additional criteria described later
determine which will be retained and which discarded.

One last conventional aspect of this matcher is that every NState records
the starting and ending offsets, within the input string, corresponding
to parenthesized subexpression groups encountered previously along that
NState's path through the SNFA.  If the NState ultimately leads to a match,
these recorded starting and ending offsets will become the rm_so/rm_eo
fields of the matcher's output.

This is all very conventional, so what is different about regular expression
matching using the SNFA?

  * Each NState traversing the SNFA records a stack of integer values
    that drive disambiguation of POSIX subpattern matches.  In contrast
    to the stacked automata of parsing theory, such as LR parsers, the
    stacks stored in NStates traversing the SNFA are finite and bounded.
    The NState stacks are held in the same storage as the remembered
    starting and ending offsets of parenthesized subexpressions, and
    record additional information about the match.

    Importantly, when comparing two NStates that have reached the same
    node in order to decide which NState will be retained and which
    will be discarded, only the NStates' initial starting offsets and
    their stack contents will be compared.  The recorded starting and
    ending offsets of parenthesized subexpressions do not participate
    in the decisions of which NStates to retain or discard!

  * The SNFA contains special nodes types recording the syntactic block
    structure of the original regular expression, with structure-delimiting
    nodes at the entry- and exit-points of alternations, closures/reptitions,
    and parenthesized subexpressions.  By contrast, the NFAs in traditional
    Thompson's construction do not retain this structure.

    Each node of the SNFA is also labeled with its stack depth within the
    block structure.  Stack entries are pushed when traversing edges from
    structure-entry nodes to interior nodes inside the structures, and
    are popped when departing from structure-exit nodes to nodes outside
    of the block.

  * The epsilon-closure algorithm is modified to respect the SNFA block
    structure as follows: the epsilon closure of all (node, NState)
    tuples inside each structured block is exhaustively expanded
    before any structure-exiting edges are followed.  This invariant
    ensures that any NState exiting a block-structured construct at a
    particular character boundary has been compared to all other possible
    competing NStates before it "escapes" to downstream/outside nodes.
    In other words, at each input character boundary, only the "best
    match" to any block-structured construct survives to escape from
    each successively less-nested level of the regular expression's
    subexpression structure.  This is important because when stack
    entries are popped at structure-exiting nodes, the stack entries
    needed to prioritize NStates with respect to the constraints of the
    now-exited structure will be lost.

    There are a variety of ways that this ordering constraint on epsilon
    closure evaluation could be implemented.  In MinRX it is enforced
    by numbering the nodes from left to right according to the lexical
    position in the original regular expression, such that all structure-
    exiting nodes are numbered higher than any nodes in the interiors of
    the structures they are exiting.  Then the queue of states waiting
    to be examined in the conventional epsilon-closure algorithm is
    replaced with a *priority* queue of states to be examined, so that
    of the not-yet-processed nodes, the lowest-numbered node will always
    be processed first.

  * In order to bound the storage of the search, whenever two NStates
    reach the same node in the SNFA, only one is retained.  Recall that
    NStates record the starting offset in the input string, their stacks,
    and the starting and ending offsets of parenthesized sub-expressions
    encountered previously in the history of the NState.  When comparing
    two NStates to pick the winner at a particular SNFA node, if one
    of the NStates has an earlier starting offset than the other, that
    NState will win.  Otherwise if both NStates have the same starting
    offset, then the NState stacks will be compared to choose the winner.

    The SNFA is constructed with the extremely important property that
    at every node, the stack layouts of different arriving NStates
    will be identical.  The stack comparison rule then is that stack
    entries are compared in lexical scope order, from outermost (oldest)
    stack levels to inner (youngest) stack levels.  At each stack level,
    if the stack entries at that level of the two competing NStates
    differ, the NState with the numerically larger stack entry value
    will be chosen as the winner.  Otherwise, as long as corresponding
    stack entries remain equal the comparison proceeds to increasingly
    inner stack levels.

    Comparing stack entries lexically from outermost to innermost
    corresponds to the POSIX regular expression requirement that the
    solution that maximizes the overall "outer" position and length of
    the whole regular expression takes precedence over finding maximum
    solution(s) of the more-local subpatterns, and this idea applies
    recursively to subpatterns of the subpatterns and so on.

In order to develop an intuition for how this works, we will look at
specific node types used in the syntax-directed translation of regular
expressions to MinRX SNFA nodes.  The translation scheme is almost
completely traditional:

* xlate[[ a|b ]]	=>	FORK xlate[[ a ]] GOTO xlate[[ b ]] JOIN
* xlate[[ a+ ]]		=>	LOOP xlate[[ a ]] NEXT
* xlate[[ ab ]]		=>	xlate[[ a ]] xlate[[ b ]]
* xlate[[ (a) ]]	=>	SUBL xlate[[ a ]] SUBR

Compared to classic Thompson's construction, the only difference above is
that parentheses in the source regular expression are translated into
epsilon-matching SUBL/SUBR nodes in the SNFA, whereas in the traditional
algorithm parentheses do not appear in the output NFA at all.

All of the node types mentioned above (FORK, GOTO, JOIN, LOOP, NEXT, SUBL,
and SUBR) are epsilon-matching node types.  All of the action of POSIX
subexpression selection happens at these epsilon-matching nodes.  The
actual character-matching nodes turn out to be not very interesting!

Now follows a description of the stack frames pushed and popped by each
of the structure-entering and structure-existing node types in MinRX:

  * A FORK node pushes a single stack entry, and a JOIN node pops it.
    The interior nodes of the FORK...JOIN construct as well as the JOIN
    node itself therefore have a stack depth 1 greater than the stack
    depth of the FORK node.  The FORK node additionally splits each
    incoming NState into two outgoing NStates for the left and right
    branches of the regular expression alternatives.  The value of the
    stack entry that is pushed is -1 on the NState sent to the left
    branch of the alternative, and -2 on the NState sent to the right
    branch of the alternative.  Then when the stacks of NStates exiting
    the alternative are compared upon arriving at the JOIN node at any
    particular character boundary in the search string, in the absence
    of any overriding constraints inherited from enclosing structures
    the choose-greater rule in the FORK's stack entry comparison will
    cause NStates joining from the left branch to take precedence over
    NStates joining from the right branch.  This implements the POSIX
    rule preferring the left alternative.

    In order to minimize maximum stack depth, and since regular expression
    alternatives are equally left- and right-associative, MinRX actually
    supports FORK...JOIN constructs with arbitrarily many contained
    alternatives (separated by GOTO nodes) and pushes stack entry values
    of -1, -2, -3, and so on in each successive alternative.

  * A SUBL node pushes a single stack entry and SUBR pops it.  As with
    FORK...JOIN, the interior nodes of SUBL...SUBR therefore have a stack
    depth 1 greater than the stack depth of the SUBL node.  The value
    of the stack entry that is pushed is the offset within the string at
    the current point in the match at which the SUBL node is traversed.
    The choose-greater rule in stack entry comparison will ensure that
    if two NStates exiting a SUBR at a particular character boundary
    are not otherwise disambiguated by inherited outer constraints,
    then the NState whose SUBL occured at a *later* point in the input
    string will be chosen.  In other words, the greater-than stack entry
    comparison rule chooses the NState corresponding to the SHORTER of
    the two exiting matches so far.

    Wait, what?  Isn't the POSIX requirement to recursively find LONGEST
    matches?  What's this shortest business doing???  The key observation
    is that preferring the SHORTEST match for SUBL...SUBR has the effect
    of maximizing the length of input string previously matched to the
    LEFT of the SUBL.  This rule prioritizes longer matches for earlier
    subpatterns in the regular expression.

    The stack frame pushed by SUBL serves an additional purpose besides
    picking winners: when a SUBR node corresponding to a user-inserted
    closing parenthesis is exited, the starting string position is popped
    from the stack and written, together with the current string position,
    into the NState's vector of recorded POSIX subexpression starting and
    ending offsets.  So (start, end) offsets don't appear in the NState's
    subexpression position vector until the NState has actually completed
    matching the entire subexpression.

  * LOOP...NEXT constructs are by far the most complicated and push three
    entries on the stack.  The outermost stack entry is the start offset
    (within the input string) at the time of initial entry to the loop.
    The next middle entry is the negated repeat count.  Finally the
    innermost stack entry is the starting offset of the most recent
    iteration of the loop.  When disambiguating multiple loop exits,
    these stack entries and their positions have the following effects:

      * The outermost stack entry, the position of the start of the loop,
	ensures that the overall shortest instance of the loop exiting
	at any character boundary will be picked, thus maximizing the
	length of material matched prior to the loop entry, as was also
	previously seen with the rule for SUBL...SUBR.

      * The next stack entry, the negated repeat count, ensures that
	for otherwise identical-length loop matches, the match with the
	fewest iterations will be chosen.  This corresponds to maximizing
	the lengths of earlier iterations.

      * Finally the last stack entry, the most recent loop start offset,
	ensures that in the case of identical repeat counts, the shortest
	match for the last repetition will be chosen, again corresponding
	to maximizing the length of earlier iterations.

    As with SUBL...SUBR, the stack entries belonging to LOOP...NEXT serve
    multiple uses.  The stacked most-recent-iteration starting offset
    is also used to eliminate repeated consecutive empty iterations
    of the loop.

That's (almost) all there is to it!

There is one potential refinement in the translation scheme that has not
yet been discussed that pertains to the associativity of concatenation.

Consider a regular expression of the form ABC, where A, B, and C
are subpatterns all of which can match material of variable length.
POSIX requires finding the leftmost longest overall solution to ABC.
But if for a particular search string there are multiple solutions for
the lengths of A, B, and C that yield the the same leftmost-longest
overall solution for ABC, which should be chosen?  Either we can try
to maximize AB at the expense of shortening C, or else we can try
to maximize A at the expense of shortening BC.

It turns out the POSIX standard is ambiguous about this situation.
The grammar in the standard for concatenated regular expressions is a
left-associative grammar.  However, there is an example in the rationale
(not officially part of the standard...) that assumes concatenation is
is right-associative.

The SNFA approach can implement either option for the associativity
of concatenation.  The default stack frames and translation scheme
described above turn out to implement left-associative concatenation:
material farther to the left is always maximized first, so in ABC,
AB will be maximized at the expense of C.

However the translation scheme can be modified to "insert parentheses"
as follows:

* xlate[[ abc ]]	=>	xlate[[ a ]] SUBL xlate[[ b ]] xlate[[ c ]] SUBR

At the cost of extra stack levels and epsilon transitions, now A will
be maximized at the expense of BC, corresponding to right-associativity.
This is achieved due to the stack entry string offset value pushed at SUBL
forcing the minimization of SUBL b c SUBR in favor of material to the
left of the SUBL.  (We would mark the extra SUBL...SUBR nodes inserted
in this fashion as invisible so that they don't show up as user-visible
numbered subexpressions with recorded positions in the output.)

MinRX currently implements left-associative concatentation, since it is
cheaper at both runtime and compile time, and is also consistent with the
behaviour of the repeated self-concatenation in duplication operators.
If there is popular demand for right-associative concatenation, or if
a future edition of the standard explicitly specifies right-associative
concatenation, that can be implemented in MinRX with a modest code change.

Part II: Reconciling non-greedy repetition operators with longest matches

POSIX 2024 introduced "non-greedy" versions of the ? * and + operators,
named ??, *?, +?, and inspired by the similar operators in Perl-derived
backtracking "regular expression" matchers.  (Note that Perl "regular
expressions" are a superset of true regular expressions.)

POSIX 2024 fails to fully specify the behavior of these non-greedy
constructs, but does express the intent that they should enable finding
"shortest matches" rather than longest matches.  The standard does
provides a few examples of expected behavior, which MinRX matches.

Finding "shortest matches" is pretty much in direct conflict with all the
rest of POSIX regular expression semantics, which are designed to find
longest-possible matches according to rules that are equally compatible
with both automata-based as well as backtracking matcher implementations.
(Or, some might say, the POSIX semantics are equally hostile to both
automata-based and backtracking implementations!)

MinRX's solution to reconciling the POSIX longest-match principle with
the desired shortest-match non-greedy operator behavior is as follows:
For each non-greedy repetition construct, at each live NState in the
match, MinRX tracks the number of characters that have already been
matched by that particular repetition.  Once a complete match has
been reached via a path that includes non-greedy repetitions, MinRX
*continues* trying to find longer matches as usual, *except* it will
reject longer matches that would require growing any non-greedy repetition
beyond its size at the point of the initial shortest accepting match.

When non-greedy repetitions are nested inside containing non-greedy
repetitions, MinRX uses a stack of non-greedy counts to ensure that
the rules of non-greediness are recursively followed at every level
of nesting.

So for example, MinRX matching a+? against the string "aaa" will match
just the first "a", as a Perl user of non-greedy matches would expect.
This occurs because MinRX reaches an accepting state after matching
the first "a".  MinRX continues to search for longer matches, but the
only longer matches available would involve further lengthening the
non-greedy repetition, which MinRX rejects.  Eventually MinRX exhausts
remaining live NStates and is left with just the successful match to
the first "a".

By contrast, MinRX matching a+?(a|aa) against "aaa" will match "aaa":
the first "a" will be matched by the a+? (as a Perl user would expect)
and the next two "aa" will be matched by the longer branch of the (a|aa)
alternative, as a user accustomed to POSIX longest-match semantics would
expect.  In fact MinRX first finds an accepting state at length 2 by
matching the shorter "a" branch of the alternative, but MinRX is then
able to grow the match to length 3 using the longer "aa" branch of the
alternative, because that extension of the match isn't attempting to
grow any non-minimal repetition beyond its size at the point of the
shortest accepting match.

A Perl-style explicitly-backtracking matcher in the same situation, by
contrast, would match a+?(a|aa) to just the initial "aa" of the "aaa":
it would match a+? to the first "a", then it would try the "a" branch
of the alternative first, reach the end of the regexp via that branch,
and accept that solution as the first complete match that it finds.
It wouldn't even look at the "aa" branch, even though that could
lead to a longer match.  So this is an example of how the MinRX
algorithm differs from Perl regular expressions.

A key property of this approach is that the *only* interaction between
the non-greedy repetitions and the rest the matching algorithm occurs in
the pruning of NStates that would grow non-greedy subpatterns too large.
Most importantly, the SNFA machinery for favoring NStates that best
satisfy the POSIX recursively-leftmost-longest requirements is untouched
by the non-greedy operator support.

So the MinRX algorithm yields shortest matches to non-greedy repetitions,
while simultaneously finding longest matches to all subpatterns that
are not inside non-greedy repetitions, and it does this regardless of
the ordering and/or nesting of the greedy and non-greedy subpatterns of
the regular expression.

In detail, MinRX introduces two new internal bracketing node types MINL
and MINR, which behave similarly to SUBL and SUBR in recording information
about what's matched by intervening nodes between them.  MinRX also
adds a vector of character counts for each non-greedy repetition to
every NState.

The purpose of MINL...MINR delimiters in the automata is to count
characters that are matched by SNFA nodes inside non-greedy repetitions.
Upon traversing a MINL node, MinRX pushes the current match offset onto
the SNFA stack.  Upon reaching the paired MINR node, MinRX subtracts
the match offset saved on the stack from the current match offset, and
adds that many characters to the cumulative count for the corresponding
minimal repetition.

When multiple paths reach the same NState with different lengths for
the minimal repetitions, MinRX favors the path with smaller count(s)
and prunes the path with larger count(s).  The NState pruning to favor
shorter paths for non-greedy repetitions has higher priority than NState
pruning that occurs to select in favor of leftmost-longest matches.
In this way, MinRX is constantly selecting in favor of solutions that
minimize the non-greedy repetitions, without otherwise breaking POSIX
conformance for cases that have no non-greedy repetitions.

When an accepting state is found, MinRX freezes the top-level minimal
repetition count, prohibiting subexpressions inside minimal repetitions
from matching any more characters.  With this limitation enforced,
MinRX continues to search forward for additional accepting states of
even longer matches, but discarding any states that would increase the
count of characters matched by minimal repetitions.  Eventually MinRX
exhausts the remaining live states, and what's left is a solution for
the longest match with the minimal repetitions fixed at the length of
their shortest possible solution.

Part III: Some caveats

  * This approach does not currently address the problem of POSIX Basic
    Regular Expressions including back-references.  I view BREs with
    backreferences as an (almost) completely unrelated problem, since
    they do not correspond to finite automata at all.  The algorithm
    described here could probably be straightforwardly modified to search
    for backreference expressions, but would lose the property that the
    maximum number of NStates in flight is equal to the size of the NFA,
    and it would almost certainly require exponential space even in
    relatively simple cases, and so would be unlikely to be generally usable.

  * It should be noted this algorithm has not yet been proven correct.
    However, it has no "special cases" and has passed a plethora of published
    tests, including a number tests that trip up almost all other extant
    attempts to implement POSIX ERE matchers.  I have high hopes for the
    ultimate success of this algorithm given the simplicity.

Part IV: Future work

  * Correctness proof and/or fix bugs until correctness proof is possible.
    (Or give up on this approach and look for new ideas...)

  * Implement a caching-DFA-like matcher based on this approach.  Certainly
    there is no direct DFA implementation, since NState stacks containing
    arbitrary counts would map to infinite numbers of automaton states.
    But there may be tricks to hoist count parameters out of the automaton
    states, or perhaps just cache (and regenerate upon demand) a finite
    subset of the states of a "Deterministic Infinite Automaton".
